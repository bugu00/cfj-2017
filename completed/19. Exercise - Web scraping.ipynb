{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's scrape some death row data\n",
    "\n",
    "Texas executes a lot of criminals, and it has a [web page](https://www.tdcj.state.tx.us/death_row/dr_offenders_on_dr.html) that keeps track of people on its death row.\n",
    "\n",
    "Using what you've learned so far, let's scrape this table into a CSV. Then we're going write a function to grab a couple pieces of additional data from the inmates' detail pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and parse the summary page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the URL to request\n",
    "URL = 'https://www.tdcj.state.tx.us/death_row/dr_offenders_on_dr.html'\n",
    "\n",
    "# get that page\n",
    "page = requests.get(URL)\n",
    "\n",
    "# turn the page text into soup\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# find the table of interest\n",
    "table = soup.find('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over the table rows and write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find all table rows (skip the first one)\n",
    "rows = table.find_all('tr')[1:]\n",
    "\n",
    "# open a file to write to\n",
    "with open('death-row.csv', 'w') as outfile:\n",
    "    \n",
    "    # create a writer object\n",
    "    writer = csv.DictWriter(outfile, fieldnames=['id', 'link', 'last', 'first', 'dob', 'sex',\n",
    "                                                 'race', 'date_received', 'county', 'offense_date'])\n",
    "    \n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        off_id = cells[0].string\n",
    "        link = 'https://www.tdcj.state.tx.us/death_row/' + cells[1].a['href']\n",
    "        last = cells[2].string\n",
    "        first = cells[3].string\n",
    "        dob = cells[4].string\n",
    "        sex = cells[5].string\n",
    "        race = cells[6].string\n",
    "        date_received = cells[7].string\n",
    "        county = cells[8].string\n",
    "        offense_date = cells[9].string\n",
    "        writer.writerow({\n",
    "            'id': off_id,\n",
    "            'link': link,\n",
    "            'last': last,\n",
    "            'first': first,\n",
    "            'dob': dob,\n",
    "            'sex': sex,\n",
    "            'race': race,\n",
    "            'date_received': date_received,\n",
    "            'county': county,\n",
    "            'offense_date': offense_date\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's write a parsing function\n",
    "\n",
    "We need a function that will take a URL of a detail page and do these things:\n",
    "\n",
    "- Open the detail page URL using `requests`\n",
    "- Parse the contents using BeautifulSoup\n",
    "- Isolate the bits of information we're interested in: height, weight, eye color, hair color, native county, native state, link to mugshot\n",
    "- Return those bits of information in a dictionary\n",
    "\n",
    "A couple things to keep in mind: Not every inmate will have every piece of data. Also, not every inmate has an HTML detail page to parse -- the older ones are a picture. So we'll need to work around those limitations.\n",
    "\n",
    "We shall call our function `fetch_details()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_details(url):\n",
    "\n",
    "    # create a dictionary with some default values\n",
    "    # as we go through, we're going to add stuff to it\n",
    "    # (if you want to explore further, there is actually\n",
    "    # a special kind of dictionary called a \"defaultdict\" to\n",
    "    # handle this use case) =>\n",
    "    # https://docs.python.org/3/library/collections.html#collections.defaultdict\n",
    "\n",
    "    out_dict = {\n",
    "        'Height': None,\n",
    "        'Weight': None,\n",
    "        'Eye Color': None,\n",
    "        'Hair Color': None,\n",
    "        'Native County': None,\n",
    "        'Native State': None,\n",
    "        'mug': None\n",
    "    }\n",
    "    \n",
    "    # partway down the page, the links go to JPEGs instead of HTML pages\n",
    "    # we can't parse images, so we'll just return the empty dictionary\n",
    "    if not url.endswith('.html'):\n",
    "        return out_dict\n",
    "    \n",
    "    # get the page\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # soup the HTML\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    # find the table of info\n",
    "    table = soup.find('table', {'class': 'tabledata_deathrow_table'})\n",
    "    \n",
    "    # target the mugshot, if it exists\n",
    "    mug = table.find('img', {'class': 'photo_border_black_right'})\n",
    "    \n",
    "    # if there is a mug, grab the src and add it to the dictionary\n",
    "    if mug:\n",
    "        out_dict['mug'] = 'http://www.tdcj.state.tx.us/death_row/dr_info/' + mug['src']\n",
    "\n",
    "        \n",
    "    # get a list of the \"label\" cells\n",
    "    # on some pages, they're identified by the class 'tabledata_bold_align_right_deathrow'\n",
    "    # on others, they're identified by the class 'tabledata_bold_align_right_unit'\n",
    "    # so we pass it a list of possible classes\n",
    "    label_cells = table.find_all('td', {'class': ['tabledata_bold_align_right_deathrow',\n",
    "                                                  'tabledata_bold_align_right_unit']})\n",
    "\n",
    "    # gonna do some fanciness here in the interests of DRY =>\n",
    "    # a list of attributes we're interested in -- should match exactly the text inside the cells of interest\n",
    "    attr_list = ['Height', 'Weight', 'Eye Color', 'Hair Color', 'Native County', 'Native State']\n",
    "\n",
    "    # loop over the list of label cells that we targeted earlier\n",
    "    for cell in label_cells:\n",
    "        \n",
    "        clean_label_cell_text = cell.text.strip()\n",
    "        \n",
    "        # check to see if the cell text is in our list of attributes\n",
    "        if clean_label_cell_text in attr_list:\n",
    "            \n",
    "            # if so, find the value -- go up to the tr and search for the other td --\n",
    "            # and add that attribute to our dictionary\n",
    "            value_cell_text = cell.parent.find('td', {'class': 'tabledata_align_left_deathrow'}).text.strip()\n",
    "            \n",
    "            out_dict[clean_label_cell_text] = value_cell_text\n",
    "\n",
    "    # return the dictionary to the script\n",
    "    return(out_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "Now that we have our parsing function, we can:\n",
    "\n",
    "- Open and read the CSV files of summary inmate info (the one we just scraped)\n",
    "- Open and write a new CSV file of detailed inmate info\n",
    "\n",
    "As we loop over the summary inmate data, we're going to call our new parsing function on the detail URL in each row. Then we'll combine the dictionaries (data from the row of summary data + new detailed data) and write out to the new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open the CSV file to read from and the one to write to\n",
    "with open('death-row.csv', 'r') as infile, open('death-row-details.csv', 'w') as outfile:\n",
    "    \n",
    "    # create a reader object\n",
    "    reader = csv.DictReader(infile)\n",
    "    \n",
    "    # the output headers are goind to be the headers from the summary file\n",
    "    # plus a list of new attributes\n",
    "    headers = reader.fieldnames + ['Height', 'Weight', 'Eye Color', 'Hair Color',\n",
    "                                   'Native County', 'Native State', 'mug']\n",
    "\n",
    "    # create the writer object\n",
    "    writer = csv.DictWriter(outfile, fieldnames=headers)\n",
    "    \n",
    "    # write the header row\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # loop over the rows in the input file\n",
    "    for row in reader:\n",
    "        \n",
    "        # print the inmate's name (so we can keep track of where we're at)\n",
    "        # helps with debugging, too\n",
    "        print(row['first'], row['last'])\n",
    "        \n",
    "        # call our function on the URL in the row\n",
    "        deets = fetch_details(row['link'])        \n",
    "        \n",
    "        # add the two dicts together by\n",
    "        # unpacking them inside a new one\n",
    "        # and write out to file\n",
    "        writer.writerow({**row, **deets})\n",
    "        \n",
    "        time.sleep(2)\n",
    "    \n",
    "    print('---')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
