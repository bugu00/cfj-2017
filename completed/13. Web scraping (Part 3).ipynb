{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's scrape the IRE homepage\n",
    "\n",
    "Our goal: Print out the headlines from the [IRE home page](https://ire.org/).\n",
    "\n",
    "[`requests`](http://docs.python-requests.org/en/master/) is a handy third-party library for making HTTP requests. It does the same thing your browser does when you type in a URL and hit enter -- sends a message to a server and requests a copy of the page -- but it allows us to do this programatically instead of pointing and clicking. For our purposes today, we're interested in the library's `get` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and parse the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the `get()` method to fetch a copy of the IRE home page\n",
    "ire_page = requests.get('http://ire.org')\n",
    "\n",
    "# feed the text of the web page to a BeautifulSoup object\n",
    "soup = BeautifulSoup(ire_page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target the headlines\n",
    "\n",
    "View source on the IRE homepage and find the headlines. What's the pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a list of headlines we're interested in\n",
    "heds = soup.find_all('h1', {'class': 'title1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over the heds, printing out the text\n",
    "\n",
    "You can drill down into a nested tag using a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North Korean workers prep seafood going to US stores, restaurants\n",
      "Police officers convicted of serious crimes still on the job\n",
      "Digital Editor (The Center for Public Integrity)\n",
      "Data Visualization Developer (The Hechinger Report )\n",
      "Judges steer defendants into work camps for private industry\n",
      "Lax oversight leaves FAA systems ripe for abuse\n",
      "Investigative Reporter (The Courier-Journal)\n",
      "Resources for covering mass shootings\n"
     ]
    }
   ],
   "source": [
    "for hed in heds:\n",
    "    print(hed.a.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Print the links\n",
    "\n",
    "Your mission: Loop over the headlines and print the links (the `href` portion of the tag) for each one. You can access tag attributes like you'd access values in a dictionary. (This could require some Googling.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
